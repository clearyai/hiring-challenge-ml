{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR - PDF to Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import subprocess\n",
    "# import glob\n",
    "# import os\n",
    "\n",
    "# # Define the input and output directories\n",
    "# input_folder = \"/Users/scottwillis/Documents/Dev/hiring-challenge-ml/docs\"\n",
    "# output_folder = \"/Users/scottwillis/Documents/Dev/hiring-challenge-ml/docs_markdown\"\n",
    "\n",
    "# # Replace spaces with underscores in PDF filenames\n",
    "# pdf_files = glob.glob(f\"{input_folder}*.pdf\")\n",
    "# for file_path in pdf_files:\n",
    "#     directory, file_name = os.path.split(file_path)\n",
    "#     new_file_name = file_name.replace(' ', '_')\n",
    "#     new_file_path = os.path.join(directory, new_file_name)\n",
    "#     os.rename(file_path, new_file_path)\n",
    "\n",
    "# # Run subprocess of nougat\n",
    "# pdf_files = glob.glob(f\"{input_folder}/*.pdf\")\n",
    "# for pdf_file in pdf_files:\n",
    "#     command = (f\"nougat {pdf_file} --out {output_folder} --markdown\")\n",
    "#     subprocess.run(command, shell=True, check=True)\n",
    "\n",
    "# 73min"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OCR - PDF to HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Define the input and output directories\n",
    "input_folder = \"/Users/scottwillis/Documents/Dev/hiring-challenge-ml/docs\"\n",
    "output_folder = \"/Users/scottwillis/Documents/Dev/hiring-challenge-ml/docs_html\"\n",
    "\n",
    "# Replace spaces with underscores in PDF filenames\n",
    "pdf_files = glob.glob(f\"{input_folder}*.pdf\")\n",
    "for file_path in pdf_files:\n",
    "    directory, file_name = os.path.split(file_path)\n",
    "    new_file_name = file_name.replace(' ', '_')\n",
    "    new_file_path = os.path.join(directory, new_file_name)\n",
    "    os.rename(file_path, new_file_path)\n",
    "\n",
    "# Run subprocess of pdftohtml with output filename based on the basename of the PDF file\n",
    "pdf_files = glob.glob(f\"{input_folder}/*.pdf\")\n",
    "for pdf_file in pdf_files:\n",
    "    # Extract the basename without the extension\n",
    "    base_name = os.path.splitext(os.path.basename(pdf_file))[0]\n",
    "    # Construct the output file path with the modified basename\n",
    "    output_file_path = os.path.join(output_folder, base_name)\n",
    "    # Construct the command with the output file path\n",
    "    command = f\"pdftohtml -skipinvisible {pdf_file} {output_file_path}\"\n",
    "    subprocess.run(command, shell=True, check=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a csv data structure from the html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "input_folder = \"/Users/scottwillis/Documents/Dev/hiring-challenge-ml/docs_html\"\n",
    "output_folder = \"/Users/scottwillis/Documents/Dev/hiring-challenge-ml/docs_csv\"\n",
    "\n",
    "# Loop through each folder in the output_folder\n",
    "for folder_name in os.listdir(input_folder):\n",
    "    folder_path = os.path.join(input_folder, folder_name)\n",
    "\n",
    "    # Check if it's a directory\n",
    "    if os.path.isdir(folder_path):\n",
    "        # Path to the index.html file\n",
    "        index_file_path = os.path.join(folder_path, 'index.html')\n",
    "        \n",
    "        # Read the index.html file\n",
    "        with open(index_file_path, 'r') as index_file:\n",
    "            index_soup = BeautifulSoup(index_file, 'html.parser')\n",
    "            \n",
    "            # Find all links to HTML pages\n",
    "            links = index_soup.find_all('a', href=True)\n",
    "            \n",
    "            # Initialize a list to store the data for this folder\n",
    "            data = []\n",
    "            \n",
    "            # Loop through all found links in the index.html\n",
    "            for link in links:\n",
    "                html_file_path = os.path.join(folder_path, link['href'])\n",
    "                \n",
    "                # Open and read each HTML file\n",
    "                with open(html_file_path, 'r') as file:\n",
    "                    soup = BeautifulSoup(file, 'html.parser')\n",
    "                    \n",
    "                    # Find all HTML elements\n",
    "                    for element in soup.find_all(True):\n",
    "                        # Get the element type (tag name)\n",
    "                        element_type = element.name\n",
    "                        # Get the attributes as a dictionary\n",
    "                        attributes = element.attrs\n",
    "                        \n",
    "                        # Extract class and style attributes\n",
    "                        class_attr = attributes.get('class', [])\n",
    "                        style_attr = attributes.get('style', '')\n",
    "                        \n",
    "                        # Get the text value of the element\n",
    "                        value = element.get_text(strip=True)\n",
    "                        \n",
    "                        # Append the data to the list\n",
    "                        data.append({\n",
    "                            \"ElementType\": element_type,\n",
    "                            \"Class\": class_attr,\n",
    "                            \"Style\": style_attr,\n",
    "                            \"Value\": value\n",
    "                        })\n",
    "            \n",
    "            # Create a DataFrame from the list\n",
    "            df = pd.DataFrame(data)\n",
    "            \n",
    "            # Save the DataFrame to a CSV file named after the folder\n",
    "            output_csv_path = os.path.join(output_folder, f\"{folder_name}.csv\")\n",
    "            df.to_csv(output_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import base64\n",
    "import random\n",
    "\n",
    "input_folder = \"/Users/scottwillis/Documents/Dev/hiring-challenge-ml/docs_csv\"\n",
    "output_folder = \"/Users/scottwillis/Documents/Dev/hiring-challenge-ml/docs_df\"\n",
    "\n",
    "# Create an empty DataFrame to store the concatenated data\n",
    "final_df = pd.DataFrame(columns=['ID', 'Filename', 'Section', 'Subsection', 'Body'])\n",
    "\n",
    "for file in os.listdir(input_folder):\n",
    "    df = pd.read_csv(os.path.join(input_folder, file))\n",
    "    df['Filename'] = file\n",
    "    \n",
    "    df = df[df['ElementType'] == 'span']\n",
    "\n",
    "    df['Class'] = df['Class'].apply(lambda x: x.strip(\"[f']\"))\n",
    "    df = df.dropna(subset=['Class'])\n",
    "    df['Class'] = df['Class'].astype(int)\n",
    "    \n",
    "    # Standardize the Class column\n",
    "    min_class = df['Class'].min()\n",
    "    df['Class'] = df['Class'].apply(lambda x: min(x - min_class + 1, 3))\n",
    "\n",
    "    cols = ['Filename', 'Class', 'Value']\n",
    "    df = df[cols]\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    # Generate a random base64 id for each row\n",
    "    df['ID'] = [base64.b64encode(os.urandom(6)).decode('utf-8') for _ in range(len(df))]\n",
    "    \n",
    "    # Initialize variables to store the concatenated values\n",
    "    prev_class_type = 0\n",
    "    section_value = \"\"\n",
    "    subsection_value = \"\"\n",
    "    body_value = \"\"\n",
    "    d = dict()\n",
    "    \n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        class_type = row['Class']\n",
    "        value = row['Value']\n",
    "        \n",
    "        # Concatenate the value with the current column\n",
    "        if class_type == 1:\n",
    "            section_value += value\n",
    "        elif class_type == 2:\n",
    "            subsection_value += value\n",
    "        elif class_type == 3:\n",
    "            body_value += value\n",
    "    \n",
    "        # Assign the concatenated values to the corresponding columns\n",
    "        # When triggered by Class change or end of Body\n",
    "        if class_type != prev_class_type or (class_type == 3 and (body_value.endswith(';') or body_value.endswith('.'))):\n",
    "            if class_type == 1:\n",
    "                d['Section'] = section_value\n",
    "            elif class_type == 2:\n",
    "                d['Subsection'] = subsection_value\n",
    "            elif class_type == 3:\n",
    "                d['Body'] = body_value\n",
    "            \n",
    "            if len(d.keys()) == 3:\n",
    "                d['ID'] = row['ID']\n",
    "                d['Filename'] = row['Filename']\n",
    "                final_df = pd.concat([final_df, pd.DataFrame([d])], ignore_index=True)\n",
    "                body_value = \"\"\n",
    "                prev_class_type = 0\n",
    "                d.pop('Body', None)\n",
    "                d.pop('ID', None)\n",
    "                d.pop('Filename', None)\n",
    "        \n",
    "        prev_class_type = class_type\n",
    "    \n",
    "# Save the final DataFrame to a CSV file\n",
    "output_csv_path = os.path.join(output_folder, \"data.csv\")\n",
    "final_df.to_csv(output_csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
